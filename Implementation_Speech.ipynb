{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2a86a9e",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8fa1f0b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "model3 = tf.keras.models.load_model(r'model3.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a50613",
   "metadata": {},
   "source": [
    "# Video 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "65d33618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Writing audio in result1.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "import moviepy.editor as mp\n",
    "\n",
    "clip = mp.VideoFileClip(r\"Test1.mp4\")\n",
    "clip.audio.write_audiofile(r\"result1.wav\")\n",
    "\n",
    "r = sr.Recognizer()\n",
    "audio = sr.AudioFile(\"result1.wav\")\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9d0bc695",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step\n",
      "Predicted emotion: surprise\n",
      "Probabilities:\n",
      "fear: 14.66%\n",
      "disgust: 12.15%\n",
      "neutral: 12.14%\n",
      "happy: 15.34%\n",
      "sadness: 12.18%\n",
      "surprise: 21.18%\n",
      "angry: 12.36%\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# Load a new audio file\n",
    "new_audio_file = r\"result1.wav\"  # Change this to the path of your new audio file\n",
    "x, sr = librosa.load(new_audio_file, res_type='kaiser_fast', sr=44000)\n",
    "\n",
    "# Define length_chosen\n",
    "length_chosen = 130307\n",
    "\n",
    "# Pad or truncate audio data to match length_chosen\n",
    "if x.shape[0] > length_chosen:\n",
    "    new = x[:length_chosen]\n",
    "elif x.shape[0] < length_chosen:\n",
    "    pad_width = math.ceil((length_chosen - x.shape[0]) / 2)\n",
    "    new = np.pad(x, (pad_width, pad_width), mode='median')\n",
    "else:\n",
    "    new = x\n",
    "\n",
    "# Extract MFCC features\n",
    "mfcc = librosa.feature.mfcc(y=new, sr=44000, n_mfcc=40)\n",
    "mfcc = mfcc.T\n",
    "\n",
    "# Reshape MFCC features\n",
    "mfcc = mfcc.reshape(1, mfcc.shape[0], mfcc.shape[1])\n",
    "\n",
    "# Make prediction\n",
    "p = model3.predict(mfcc)\n",
    "\n",
    "# Define emotion labels\n",
    "emotion_labels = {\n",
    "    0: 'fear',\n",
    "    1: 'disgust',\n",
    "    2: 'neutral',\n",
    "    3: 'happy',\n",
    "    4: 'sadness',\n",
    "    5: 'surprise',\n",
    "    6: 'angry'\n",
    "}\n",
    "\n",
    "# Calculate softmax probabilities for each class\n",
    "probabilities = np.exp(p) / np.sum(np.exp(p), axis=-1)\n",
    "\n",
    "# Get predicted emotion with maximum probability\n",
    "predicted_emotion_index = np.argmax(probabilities)\n",
    "predicted_emotion = emotion_labels[predicted_emotion_index]\n",
    "\n",
    "# Get probability of correctness for each class\n",
    "correctness_probabilities = probabilities[0]\n",
    "\n",
    "# Output the predicted emotion with its corresponding probability\n",
    "print(\"Predicted emotion:\", predicted_emotion)\n",
    "print(\"Probabilities:\")\n",
    "for emotion_idx, emotion_label in emotion_labels.items():\n",
    "    print(f\"{emotion_label}: {correctness_probabilities[emotion_idx] * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b70ca5b",
   "metadata": {},
   "source": [
    "# Video 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7e3b8774",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Writing audio in result2.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "import moviepy.editor as mp\n",
    "\n",
    "clip = mp.VideoFileClip(r\"Test2.mp4\")\n",
    "clip.audio.write_audiofile(r\"result2.wav\")\n",
    "\n",
    "r = sr.Recognizer()\n",
    "audio = sr.AudioFile(\"result2.wav\")\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b4b70052",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "Predicted emotion: disgust\n",
      "Probabilities:\n",
      "fear: 12.05%\n",
      "disgust: 20.30%\n",
      "neutral: 12.05%\n",
      "happy: 19.44%\n",
      "sadness: 12.05%\n",
      "surprise: 12.06%\n",
      "angry: 12.05%\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# Load a new audio file\n",
    "new_audio_file = r\"result2.wav\"  # Change this to the path of your new audio file\n",
    "x, sr = librosa.load(new_audio_file, res_type='kaiser_fast', sr=44000)\n",
    "\n",
    "# Define length_chosen\n",
    "length_chosen = 130307\n",
    "\n",
    "# Pad or truncate audio data to match length_chosen\n",
    "if x.shape[0] > length_chosen:\n",
    "    new = x[:length_chosen]\n",
    "elif x.shape[0] < length_chosen:\n",
    "    pad_width = math.ceil((length_chosen - x.shape[0]) / 2)\n",
    "    new = np.pad(x, (pad_width, pad_width), mode='median')\n",
    "else:\n",
    "    new = x\n",
    "\n",
    "# Extract MFCC features\n",
    "mfcc = librosa.feature.mfcc(y=new, sr=44000, n_mfcc=40)\n",
    "mfcc = mfcc.T\n",
    "\n",
    "# Reshape MFCC features\n",
    "mfcc = mfcc.reshape(1, mfcc.shape[0], mfcc.shape[1])\n",
    "\n",
    "# Make prediction\n",
    "p = model3.predict(mfcc)\n",
    "\n",
    "# Define emotion labels\n",
    "emotion_labels = {\n",
    "    0: 'fear',\n",
    "    1: 'disgust',\n",
    "    2: 'neutral',\n",
    "    3: 'happy',\n",
    "    4: 'sadness',\n",
    "    5: 'surprise',\n",
    "    6: 'angry'\n",
    "}\n",
    "\n",
    "# Calculate softmax probabilities for each class\n",
    "probabilities = np.exp(p) / np.sum(np.exp(p), axis=-1)\n",
    "\n",
    "# Get predicted emotion with maximum probability\n",
    "predicted_emotion_index = np.argmax(probabilities)\n",
    "predicted_emotion = emotion_labels[predicted_emotion_index]\n",
    "\n",
    "# Get probability of correctness for each class\n",
    "correctness_probabilities = probabilities[0]\n",
    "\n",
    "# Output the predicted emotion with its corresponding probability\n",
    "print(\"Predicted emotion:\", predicted_emotion)\n",
    "print(\"Probabilities:\")\n",
    "for emotion_idx, emotion_label in emotion_labels.items():\n",
    "    print(f\"{emotion_label}: {correctness_probabilities[emotion_idx] * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a504db1",
   "metadata": {},
   "source": [
    "# Video 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4a92ba98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Writing audio in result3.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "import moviepy.editor as mp\n",
    "\n",
    "clip = mp.VideoFileClip(r\"Test3.mp4\")\n",
    "clip.audio.write_audiofile(r\"result3.wav\")\n",
    "\n",
    "r = sr.Recognizer()\n",
    "audio = sr.AudioFile(\"result3.wav\")\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4e8c6859",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Predicted emotion: fear\n",
      "Probabilities:\n",
      "fear: 24.44%\n",
      "disgust: 12.06%\n",
      "neutral: 12.00%\n",
      "happy: 11.98%\n",
      "sadness: 12.96%\n",
      "surprise: 14.54%\n",
      "angry: 12.01%\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# Load a new audio file\n",
    "new_audio_file = r\"result3.wav\"  # Change this to the path of your new audio file\n",
    "x, sr = librosa.load(new_audio_file, res_type='kaiser_fast', sr=44000)\n",
    "\n",
    "# Define length_chosen\n",
    "length_chosen = 130307\n",
    "\n",
    "# Pad or truncate audio data to match length_chosen\n",
    "if x.shape[0] > length_chosen:\n",
    "    new = x[:length_chosen]\n",
    "elif x.shape[0] < length_chosen:\n",
    "    pad_width = math.ceil((length_chosen - x.shape[0]) / 2)\n",
    "    new = np.pad(x, (pad_width, pad_width), mode='median')\n",
    "else:\n",
    "    new = x\n",
    "\n",
    "# Extract MFCC features\n",
    "mfcc = librosa.feature.mfcc(y=new, sr=44000, n_mfcc=40)\n",
    "mfcc = mfcc.T\n",
    "\n",
    "# Reshape MFCC features\n",
    "mfcc = mfcc.reshape(1, mfcc.shape[0], mfcc.shape[1])\n",
    "\n",
    "# Make prediction\n",
    "p = model3.predict(mfcc)\n",
    "\n",
    "# Define emotion labels\n",
    "emotion_labels = {\n",
    "    0: 'fear',\n",
    "    1: 'disgust',\n",
    "    2: 'neutral',\n",
    "    3: 'happy',\n",
    "    4: 'sadness',\n",
    "    5: 'surprise',\n",
    "    6: 'angry'\n",
    "}\n",
    "\n",
    "# Calculate softmax probabilities for each class\n",
    "probabilities = np.exp(p) / np.sum(np.exp(p), axis=-1)\n",
    "\n",
    "# Get predicted emotion with maximum probability\n",
    "predicted_emotion_index = np.argmax(probabilities)\n",
    "predicted_emotion = emotion_labels[predicted_emotion_index]\n",
    "\n",
    "# Get probability of correctness for each class\n",
    "correctness_probabilities = probabilities[0]\n",
    "\n",
    "# Output the predicted emotion with its corresponding probability\n",
    "print(\"Predicted emotion:\", predicted_emotion)\n",
    "print(\"Probabilities:\")\n",
    "for emotion_idx, emotion_label in emotion_labels.items():\n",
    "    print(f\"{emotion_label}: {correctness_probabilities[emotion_idx] * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c2be24",
   "metadata": {},
   "source": [
    "# For Full Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a717db8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Predicted emotions for the video:\n",
      "\u001b[1msadness\u001b[0m\n",
      "Probabilities:\n",
      "fear: 14.26%\n",
      "disgust: 13.94%\n",
      "neutral: 13.46%\n",
      "happy: 13.00%\n",
      "sadness: 18.92%\n",
      "surprise: 12.86%\n",
      "angry: 13.56%\n",
      "\u001b[1msadness\u001b[0m\n",
      "Probabilities:\n",
      "fear: 13.04%\n",
      "disgust: 12.69%\n",
      "neutral: 14.51%\n",
      "happy: 12.71%\n",
      "sadness: 19.60%\n",
      "surprise: 13.61%\n",
      "angry: 13.83%\n",
      "\u001b[1mangry\u001b[0m\n",
      "Probabilities:\n",
      "fear: 12.22%\n",
      "disgust: 13.04%\n",
      "neutral: 12.35%\n",
      "happy: 12.24%\n",
      "sadness: 14.89%\n",
      "surprise: 13.12%\n",
      "angry: 22.15%\n",
      "\u001b[1msadness\u001b[0m\n",
      "Probabilities:\n",
      "fear: 12.09%\n",
      "disgust: 12.12%\n",
      "neutral: 12.07%\n",
      "happy: 12.07%\n",
      "sadness: 21.89%\n",
      "surprise: 16.99%\n",
      "angry: 12.77%\n",
      "\u001b[1mangry\u001b[0m\n",
      "Probabilities:\n",
      "fear: 11.86%\n",
      "disgust: 11.54%\n",
      "neutral: 11.54%\n",
      "happy: 11.54%\n",
      "sadness: 11.54%\n",
      "surprise: 11.56%\n",
      "angry: 30.44%\n",
      "\u001b[1mangry\u001b[0m\n",
      "Probabilities:\n",
      "fear: 11.47%\n",
      "disgust: 11.47%\n",
      "neutral: 11.47%\n",
      "happy: 11.47%\n",
      "sadness: 11.47%\n",
      "surprise: 11.47%\n",
      "angry: 31.17%\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import math\n",
    "import moviepy.editor as mp\n",
    "\n",
    "# Load your model (model3) and define emotion_labels as before\n",
    "import tensorflow as tf\n",
    "model3 = tf.keras.models.load_model(r'model3.h5')\n",
    "\n",
    "# Define emotion labels\n",
    "emotion_labels = {\n",
    "    0: 'fear',\n",
    "    1: 'disgust',\n",
    "    2: 'neutral',\n",
    "    3: 'happy',\n",
    "    4: 'sadness',\n",
    "    5: 'surprise',\n",
    "    6: 'angry'\n",
    "}\n",
    "\n",
    "# Define function to process audio chunks and make predictions\n",
    "def process_audio_chunk(chunk):\n",
    "    # Pad or truncate audio data to match length_chosen\n",
    "    if len(chunk) > length_chosen:\n",
    "        new_chunk = chunk[:length_chosen]\n",
    "    elif len(chunk) < length_chosen:\n",
    "        pad_width = math.ceil((length_chosen - len(chunk)) / 2)\n",
    "        new_chunk = np.pad(chunk, (pad_width, pad_width), mode='median')\n",
    "    else:\n",
    "        new_chunk = chunk\n",
    "\n",
    "    # Extract MFCC features\n",
    "    mfcc = librosa.feature.mfcc(y=new_chunk, sr=44000, n_mfcc=40)\n",
    "    mfcc = mfcc.T\n",
    "\n",
    "    # Reshape MFCC features\n",
    "    mfcc = mfcc.reshape(1, mfcc.shape[0], mfcc.shape[1])\n",
    "\n",
    "    # Make prediction\n",
    "    p = model3.predict(mfcc)\n",
    "\n",
    "    # Calculate softmax probabilities for each class\n",
    "    probabilities = np.exp(p) / np.sum(np.exp(p), axis=-1)\n",
    "\n",
    "    # Get predicted emotion with maximum probability\n",
    "    predicted_emotion_index = np.argmax(probabilities)\n",
    "    predicted_emotion = emotion_labels[predicted_emotion_index]\n",
    "\n",
    "    return predicted_emotion, probabilities.flatten()  # Returning flattened probabilities array\n",
    "\n",
    "# Load the video file\n",
    "video_file_path = \"Test3.mp4\"\n",
    "video_clip = mp.VideoFileClip(video_file_path)\n",
    "\n",
    "# Extract audio from the video\n",
    "audio_clip = video_clip.audio\n",
    "\n",
    "# Get audio parameters\n",
    "sample_rate = audio_clip.fps\n",
    "duration = audio_clip.duration\n",
    "\n",
    "# Set chunk size and length chosen\n",
    "chunk_size = 44100  # Adjust as needed\n",
    "length_chosen = 130307\n",
    "\n",
    "# Initialize variables\n",
    "total_frames = int(sample_rate * duration)\n",
    "predicted_emotions = []\n",
    "\n",
    "# Process audio in chunks\n",
    "for i in range(0, total_frames, chunk_size):\n",
    "    # Read audio chunk\n",
    "    audio_chunk = audio_clip.subclip(i / sample_rate, (i + chunk_size) / sample_rate)\n",
    "    audio_chunk = audio_chunk.to_soundarray()\n",
    "    audio_chunk = audio_chunk.mean(axis=1)  # Convert stereo to mono\n",
    "\n",
    "    # Process the audio chunk and make prediction\n",
    "    predicted_emotion, correctness_probabilities = process_audio_chunk(audio_chunk)  # Correcting the unpacking\n",
    "\n",
    "    # Store predicted emotion\n",
    "    predicted_emotions.append((predicted_emotion, correctness_probabilities))  # Storing both emotion and probabilities\n",
    "\n",
    "# Print predicted emotions and probabilities\n",
    "print(\"Predicted emotions for the video:\")\n",
    "for emotion, probabilities in predicted_emotions:\n",
    "    print(\"\\033[1m\" + emotion + \"\\033[0m\")  # Print predicted emotion in bold\n",
    "    print(\"Probabilities:\")\n",
    "    for emotion_idx, emotion_label in emotion_labels.items():\n",
    "        print(f\"{emotion_label}: {probabilities[emotion_idx] * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f3e302",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
